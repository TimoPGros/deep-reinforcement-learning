{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "## Project-Structure\n",
    "The Project-Structure is mainly oriented on the p1_navigation project. There are 5 different classes:\n",
    "- OUNoise\n",
    "- Critics_network\n",
    "- Actor_network\n",
    "- ReplayBuffer\n",
    "- Agent\n",
    "\n",
    "### OUNoise\n",
    "This class creates noise to the given dimension according to the Ornstein-Uhlenbeck process. This class was written by Markus Buchholz, https://github.com/markusbuchholz/\n",
    "\n",
    "### Critics_network\n",
    "The network constists of an input layer (33 nodes) and two hidden layers (400, 300) nodes and has an output layer (1 node). Additionally, the input from the actor is taken into account for the second hidden layer. \n",
    "\n",
    "### Actor_network\n",
    "This is a fully connected network having 33,200,150 nodes with an output layer of 4 nodes. \n",
    "\n",
    "### Replay Buffer\n",
    "This Replay Buffer basically carries over from the p1 project. \n",
    "\n",
    "### Agent\n",
    "\n",
    "Implementation of the ddpg algorithm, using experience replay and fixed targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter \n",
    "\n",
    "There are various different Hyperparameters. For the provided result, the parameters \n",
    "\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 0.99          # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "ACTOR_LR = 1e-3               # learning rate \n",
    "CRITICS_LR = 1e-3               # learning rate \n",
    "WEIGHT_DECAY = 0\n",
    "UPDATE_EVERY = 10       # how often to update the network\n",
    "\n",
    "\n",
    "### Algorithm\n",
    "The implemented algorithm can be found unter ddpg and samples n_episodes many episodes with length t_max from the environment. It calls the agents step method to save the samples and to train the agent. Furthermore, the return of the last 100 episodes is saved\n",
    "\n",
    "### Improvements\n",
    "One option to improve would be to implement A3C instead of ddpg.\n",
    "\n",
    "Furthermore, there is the option to implement multiple agents, i.e. unsing the 20 robot version. \n",
    "\n",
    "On top of that, a grid search could find the optimal Hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
